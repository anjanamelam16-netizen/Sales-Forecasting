{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "\n",
    "import findspark\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.offline as pyo\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, col\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql import functions as F\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['sales'], color = 'blue', edgecolor = 'black',\n",
    "         bins = int(180/5))\n",
    "plt.title('Histogram of sales')\n",
    "plt.xlabel('sales')\n",
    "plt.ylabel('sales frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyo.init_notebook_mode()\n",
    "daily_sales = df.groupby('date', as_index=False)['sales'].sum()\n",
    "store_daily_sales = df.groupby(['store', 'date'], as_index=False)['sales'].sum()\n",
    "item_daily_sales = df.groupby(['item', 'date'], as_index=False)['sales'].sum()\n",
    "\n",
    "daily_sales_sc = go.Scatter(x=daily_sales['date'], y=daily_sales['sales'])\n",
    "layout = go.Layout(title='Daily sales', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\n",
    "fig = go.Figure(data=[daily_sales_sc], layout=layout)\n",
    "fig.show(renderer=\"colab\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_daily_sales_sc = []\n",
    "for store in store_daily_sales['store'].unique():\n",
    "    current_store_daily_sales = store_daily_sales[(store_daily_sales['store'] == store)]\n",
    "    store_daily_sales_sc.append(go.Scatter(x=current_store_daily_sales['date'], y=current_store_daily_sales['sales'], name=('Store %s' % store)))\n",
    "\n",
    "layout = go.Layout(title='Store daily sales', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\n",
    "fig = go.Figure(data=store_daily_sales_sc, layout=layout)\n",
    "fig.show(renderer=\"colab\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_daily_sales_sc = []\n",
    "for item in item_daily_sales['item'].unique():\n",
    "    current_item_daily_sales = item_daily_sales[(item_daily_sales['item'] == item)]\n",
    "    item_daily_sales_sc.append(go.Scatter(x=current_item_daily_sales['date'], y=current_item_daily_sales['sales'], name=('Item %s' % item)))\n",
    "\n",
    "layout = go.Layout(title='Item daily sales', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\n",
    "fig = go.Figure(data=item_daily_sales_sc, layout=layout)\n",
    "fig.show(renderer=\"colab\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sales = df.groupby('item')['sales'].sum()\n",
    "sorted_item_sales = item_sales.sort_values(ascending=False)\n",
    "top_5_items = sorted_item_sales.head(5)\n",
    "top_5_data = df[df['item'].isin(top_5_items.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_5_daily_sales_bar = []\n",
    "for item in top_5_data['item'].unique():\n",
    "    current_item_daily_sales = top_5_data[(top_5_data['item'] == item)]\n",
    "    item_5_daily_sales_bar.append(go.Scatter(x=current_item_daily_sales['date'], y=current_item_daily_sales['sales'], name=('Item %s' % item)))\n",
    "\n",
    "layout = go.Layout(title='Item daily sales for top 5 items', xaxis=dict(title='Date'), yaxis=dict(title='Sales'))\n",
    "fig = go.Figure(data=item_5_daily_sales_bar, layout=layout)\n",
    "fig.show(renderer=\"colab\")\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = top_5_data.groupby('item')['sales'].sum()\n",
    "item_sales_bar = top_5_data.groupby('item')['sales'].sum().reset_index()\n",
    "top_items_bar = item_sales_bar.nlargest(5, 'sales')\n",
    "top_items_bar[\"item\"]=top_items_bar[\"item\"].astype(str)\n",
    "\n",
    "fig = px.bar(top_items_bar, x='item', y='sales',\n",
    "            color='item',\n",
    "             labels={''}, height=400)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show(renderer=\"colab\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_daily_sales = df.groupby(['store'], as_index=False)['sales'].sum().sort_values('sales')\n",
    "store_daily_sales[\"store\"]=store_daily_sales[\"store\"].astype(str)\n",
    "\n",
    "fig = px.bar(store_daily_sales, x='store', y='sales',\n",
    "            color='store',\n",
    "             labels={'pop':'population of Canada'}, height=400)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show(renderer=\"colab\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date=df.copy()\n",
    "df_date['year'] = df_date['date'].dt.isocalendar().year\n",
    "df_date['month'] = df_date['date'].dt.month\n",
    "df_date['day'] = df_date['date'].dt.day\n",
    "df_date['weekofyear'] = df_date['date'].dt.isocalendar().week\n",
    "df_date['dayofweek'] = df_date['date'].dt.dayofweek\n",
    "month_sales = df_date.groupby(['month'], as_index=False)['sales'].sum().sort_values('sales')\n",
    "month_sales[\"month\"]=month_sales[\"month\"].astype(int)\n",
    "\n",
    "fig = px.bar(month_sales, x='month', y='sales',\n",
    "            color='month',\n",
    "              height=400)\n",
    "fig.update_xaxes(dtick=\"M1\", tickformat=\"%Y-%m\")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show(renderer=\"colab\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_sales = df_date.groupby(['day'], as_index=False)['sales'].sum().sort_values('sales')\n",
    "day_sales[\"day\"]=day_sales[\"day\"].astype(int)\n",
    "\n",
    "fig = px.bar(day_sales, x='day', y='sales',\n",
    "            color='day',\n",
    "              height=400)\n",
    "fig.update_xaxes(dtick=\"M1\", tickformat=\"%Y-%m\")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show(renderer=\"colab\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_day_sales = df_date.groupby(['dayofweek'], as_index=False)['sales'].sum().sort_values('sales')\n",
    "week_day_sales[\"dayofweek\"]=week_day_sales[\"dayofweek\"].astype(int)\n",
    "\n",
    "fig = px.bar(week_day_sales, x='dayofweek', y='sales',\n",
    "            color='dayofweek',\n",
    "              height=400)\n",
    "fig.update_xaxes(dtick=\"M1\", tickformat=\"%Y-%m\")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show(renderer=\"colab\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_year_sales = df_date.groupby(['weekofyear'], as_index=False)['sales'].sum().sort_values('sales')\n",
    "week_year_sales[\"weekofyear\"]=week_year_sales[\"weekofyear\"].astype(int)\n",
    "fig = px.bar(week_year_sales, x='weekofyear', y='sales',\n",
    "            color='weekofyear',\n",
    "              height=400)\n",
    "\n",
    "fig.update_xaxes(dtick=\"M1\", tickformat=\"%Y-%m\")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show(renderer=\"colab\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12*2,6))\n",
    "ax=sns.boxplot(data=df, x='store', y='sales', hue='store')\n",
    "plt.xlabel('Store')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Outlier Box Plot of Sales for Each Store-Item Combination')\n",
    "ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,2,3,4,5,6,7,8,9,10])\n",
    "x=s.describe(percentiles=[.75]).T.reset_index()\n",
    "df_out=df.copy()\n",
    "df_describe=df_out[['store','sales']].groupby(['store']).apply(lambda g : g['sales'].describe(percentiles = [.75]).T).reset_index()\n",
    "df_out=df_out.merge(df_describe[['store','mean','75%']], on=['store'], how='left')\n",
    "df_out['sales_imputed'] = np.where(df_out[\"sales\"] >= df_out[\"75%\"], df_out[\"mean\"], df_out[\"sales\"])\n",
    "df_out = df_out[['date', 'store', 'item', 'sales_imputed']]\n",
    "df_out.rename(columns = {'sales_imputed':'sales'}, inplace = True)\n",
    "df_store_1=df[df['store']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = StructType([\n",
    "    StructField('date', TimestampType()),\n",
    "    StructField('item', StringType()),\n",
    "    StructField('sales', DoubleType()),\n",
    "    StructField('predictions', DoubleType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema_df, PandasUDFType.GROUPED_MAP)\n",
    "def holts(df):\n",
    "    edf = df[['date','sales']]\n",
    "    edf['date'] = pd.to_datetime(edf['date'])\n",
    "    split_date = pd.to_datetime('2017-11-30')\n",
    "    train_set=edf.loc[edf['date'] <= split_date]\n",
    "    test_set = edf.loc[edf['date'] > split_date]\n",
    "\n",
    "    train_set.set_index('date',inplace=True)\n",
    "    test_set.set_index('date',inplace=True)\n",
    "\n",
    "    train_set=train_set['sales'].resample('D').mean()\n",
    "    train_set.asfreq(\"D\")\n",
    "    test_set=test_set['sales'].resample('D').mean()\n",
    "    test_set.asfreq(\"D\")\n",
    "\n",
    "    hw_model1 = ExponentialSmoothing(train_set, trend=\"additive\", seasonal=\"additive\", seasonal_periods=365)\n",
    "    fit2 = hw_model1.fit(optimized=True)\n",
    "    pred_ts_t_HW = fit2.predict(start=test_set.index[0], end = test_set.index[-1])\n",
    "\n",
    "    predictions_hw_df = pred_ts_t_HW.reset_index().rename(columns={'index': 'date', 'pred_ts_t_HW': 'prediction'})\n",
    "    predictions_hw_df=predictions_hw_df.rename(columns={0: \"predictions\"})\n",
    "    predictions_hw_df=predictions_hw_df.merge(test_set, on='date', how='left')\n",
    "    predictions_hw_df['item'] = df['item'].iloc[0]\n",
    "    predictions_hw_df['item'] = predictions_hw_df['item'].apply(str)\n",
    "    return predictions_hw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.options(header='True', inferSchema='True').csv(f'train.csv')\n",
    "df_spark = df_spark.select(F.col(\"date\"), F.col('item'), F.col(\"sales\"))\n",
    "df_spark.printSchema()\n",
    "\n",
    "results_df = df_spark.groupby(['item']).apply(holts)\n",
    "results_df.show()\n",
    "results_df.printSchema()\n",
    "\n",
    "start = time.time()\n",
    "results_df.show()\n",
    "end = time.time()\n",
    "results_df = results_df.withColumn(\"date\", date_format(\"date\", \"yyyy-MM-dd HH:mm:ss\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holts_pandas(df):\n",
    "    edf = df[['date','sales']]\n",
    "    edf['date'] = pd.to_datetime(edf['date'])\n",
    "    split_date = pd.to_datetime('2017-11-30')\n",
    "\n",
    "    train_set=edf.loc[edf['date'] <= split_date]\n",
    "    test_set = edf.loc[edf['date'] > split_date]\n",
    "    train_set.set_index('date',inplace=True)\n",
    "    test_set.set_index('date',inplace=True)\n",
    "\n",
    "    train_set=train_set['sales'].resample('D').mean()\n",
    "    train_set.asfreq(\"D\")\n",
    "    test_set=test_set['sales'].resample('D').mean()\n",
    "    test_set.asfreq(\"D\")\n",
    "\n",
    "    hw_model1 = ExponentialSmoothing(train_set, trend=\"additive\", seasonal=\"additive\", seasonal_periods=365)\n",
    "    fit2 = hw_model1.fit(optimized=True)\n",
    "    pred_ts_t_HW = fit2.predict(start=test_set.index[0], end = test_set.index[-1])\n",
    "    predictions_hw_df = pred_ts_t_HW.reset_index().rename(columns={'index': 'date', 'pred_ts_t_HW': 'prediction'})\n",
    "    predictions_hw_df=predictions_hw_df.rename(columns={0: \"predictions\"})\n",
    "    predictions_hw_df=predictions_hw_df.merge(test_set, on='date', how='left')\n",
    "    predictions_hw_df['item'] = df['item'].iloc[0]\n",
    "    predictions_hw_df['item'] = predictions_hw_df['item'].apply(str)\n",
    "    return predictions_hw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv(f'train.csv')\n",
    "df_pandas = df_pandas[['date','item','sales']]\n",
    "\n",
    "start = time.time()\n",
    "results_pandas = df_pandas.groupby(['item']).apply(holts_pandas)\n",
    "end = time.time()\n",
    "\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spark=3.6809322834014893\n",
    "time_pd=78.33949851989746\n",
    "percent_diff=((time_pd-time_spark)/(time_pd)*100)\n",
    "print(\"Percentage diff: {0} %\\n\".format(round(percent_diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = pd.to_datetime('2017-11-30')\n",
    "pd.to_datetime(df_date['date'].max())\n",
    "train_set=df_date.loc[df_date['date'] <= split_date]\n",
    "test_set = df_date.loc[df_date['date'] > split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.set_index('date',inplace=True)\n",
    "test_set.set_index('date',inplace=True)\n",
    "\n",
    "train_set=train_set['sales'].resample('D').mean()\n",
    "test_set=test_set['sales'].resample('D').mean()\n",
    "\n",
    "train_set.asfreq(\"D\")\n",
    "test_set.asfreq(\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_model1 = ExponentialSmoothing(train_set, trend=\"additive\", seasonal=\"additive\", seasonal_periods=365)\n",
    "fit2 = hw_model1.fit(optimized=True)\n",
    "pred_ts_t_HW = fit2.predict(start=test_set.index[0], end = test_set.index[-1])\n",
    "predictions_hw_df = pred_ts_t_HW.reset_index().rename(columns={'index': 'date', 'pred_ts_t_HW': 'prediction'})\n",
    "predictions_hw_df=predictions_hw_df.rename(columns={0: \"predictions\"})\n",
    "predictions_hw_df=predictions_hw_df.merge(test_set, on='date', how='left')\n",
    "predictions_hw_df['store'] = df_date['store'].iloc[0]\n",
    "value = df_date.iloc[0]['store']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
